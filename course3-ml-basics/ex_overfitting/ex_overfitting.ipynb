{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML per previsione di dati immobiliari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dipendenze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dipendenze\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer #per applicare le trasformazioni alle colonne\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler #per normalizzare i dati\n",
    "from sklearn.preprocessing import LabelEncoder #per trasformare le variabili categoriche in numeriche\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = \"https://raw.githubusercontent.com/ProfAI/machine-learning-fondamenti/main/datasets/housing_dirty.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = df.columns.drop(\"PRICE\")\n",
    "\n",
    "y_name = \"PRICE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM\n",
      "HIGH         130\n",
      "LOW          127\n",
      "VERY HIGH    127\n",
      "MODERATE     122\n",
      "Name: count, dtype: int64\n",
      "CHAS\n",
      "NO     471\n",
      "YES     35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Verifica tipologia di dati\n",
    "\n",
    "for column in df.columns:\n",
    "    if(df[column].dtype == \"object\"):\n",
    "        print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM         0\n",
       "ZN           2\n",
       "INDUS        3\n",
       "CHAS         0\n",
       "NOX          7\n",
       "RM           5\n",
       "AGE          4\n",
       "DIS          5\n",
       "RAD          3\n",
       "TAX          2\n",
       "PTRATIO      5\n",
       "B            3\n",
       "LSTAT      199\n",
       "PRICE        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifica dati mancanti\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimozione valori mancanti nella colonna target\n",
    "\n",
    "df = df.dropna(subset=y_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimozione di colonne e righe con valori mancanti > 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM         0\n",
       "ZN           2\n",
       "INDUS        3\n",
       "CHAS         0\n",
       "NOX          7\n",
       "RM           4\n",
       "AGE          3\n",
       "DIS          4\n",
       "RAD          2\n",
       "TAX          1\n",
       "PTRATIO      4\n",
       "B            2\n",
       "LSTAT      197\n",
       "PRICE        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rimozione di righe/colonne con troppi valori mancanti (Threshold > 50%)\n",
    "\n",
    "df = df.dropna(axis=1, thresh=df.shape[0]*0.5)\n",
    "\n",
    "df = df.dropna(thresh=df.shape[1]*0.5)\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione delle pipelines di trasformazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se ci sono colonne con valori nulli e sostituisci i valori nulli con la moda o la media\n",
    "\n",
    "def replace_nulls(df):\n",
    "    for column in df.columns: \n",
    "        if(column == y_name):\n",
    "            continue\n",
    "        if df[column].dtype == \"object\": #verifica tipo di dato\n",
    "            replace_with = df[column].mode()[0]\n",
    "            df[column] = df[column].fillna(replace_with)\n",
    "        else:\n",
    "            replace_with = round(df[column].mean(), 1) #arrotondamento scelto in base ad altri valori del dataset\n",
    "            df[column] = df[column].fillna(replace_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM'] ['CHAS'] ['ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "# Split tra features numeriche e categoriche\n",
    "\n",
    "def split_features(df):\n",
    "    ## Manual\n",
    "    if(\"CHAS\" in df.columns and \"CRIM\" in df.columns):\n",
    "        categorical_ordinal_columns = [\"CRIM\"] # su cui eseguire LabelEncoding .map()\n",
    "        categorical_nominal_columns = [\"CHAS\"] # su cui eseguire OneHotEncoding pd.get_dummies()\n",
    "    else:\n",
    "        categorical_ordinal_columns = []\n",
    "        categorical_nominal_columns = []\n",
    "\n",
    "    numerical_columns = [col for col in df.columns if df[col].dtype in [\"int64\", \"float64\"]]\n",
    "\n",
    "    if(y_name in numerical_columns):\n",
    "        numerical_columns.remove(y_name)\n",
    "\n",
    "    return categorical_ordinal_columns, categorical_nominal_columns, numerical_columns\n",
    "\n",
    "categorical_ordinal_columns, categorical_nominal_columns, numerical_columns = split_features(df)\n",
    "\n",
    "print(categorical_ordinal_columns, categorical_nominal_columns, numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "\n",
    "def label_encoding(df, columns, map):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df):\n",
    "    df = (df - df.mean()) / df.std()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df):\n",
    "    for column in df.columns:\n",
    "        df = pd.get_dummies(df, columns=[column])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasformazione dei dati\n",
    "\n",
    "def transform_data(df):\n",
    "\n",
    "    replace_nulls(df)\n",
    "\n",
    "    categorical_ordinal_columns, categorical_nominal_columns, numerical_columns = split_features(df)\n",
    "\n",
    "    label_encoding(df, categorical_ordinal_columns, {\"LOW\":0, \"MODERATE\":1, \"HIGH\":2, \"VERY HIGH\":3})\n",
    "\n",
    "    df = pd.concat([df, one_hot_encoding(df[categorical_nominal_columns])], axis=1).drop(categorical_nominal_columns, axis=1)\n",
    "\n",
    "    df[numerical_columns] = scale_data(df[numerical_columns])\n",
    "\n",
    "    df[categorical_ordinal_columns] = scale_data(df[categorical_ordinal_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and target split\n",
    "\n",
    "X = df.drop(y_name, axis=1)\n",
    "Y = df[y_name]\n",
    "\n",
    "X = transform_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train test split\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(df.drop(y_name, axis=1), df[y_name], test_size=0.3)\n",
    "\n",
    "# X_train = transform_data(X_train)\n",
    "\n",
    "# X_test = transform_data(X_test)\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validazione delle performance del modello\n",
    "\n",
    "def evaluate_model(model, dataset):\n",
    "    X, Y = dataset\n",
    "\n",
    "    Y_pred = model.predict(X)\n",
    "    \n",
    "    mse = mean_squared_error(Y, Y_pred)\n",
    "    r2 = r2_score(Y, Y_pred)\n",
    "\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, Y, cv=5, pipeline=None):\n",
    "    kf = KFold(n_splits=cv, shuffle=True)\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    models = []\n",
    "\n",
    "    if pipeline is None:\n",
    "        model = Pipeline([\n",
    "            (\"poly\", PolynomialFeatures(degree=2)),\n",
    "            (\"lasso\", LinearRegression())\n",
    "        ])\n",
    "    else:\n",
    "        model = pipeline\n",
    "\n",
    "    X = X.values\n",
    "    Y = Y.values\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        r2_train = r2_score(Y_train, model.predict(X_train))\n",
    "        r2_test = r2_score(Y_test, model.predict(X_test))\n",
    "\n",
    "        train_scores.append(r2_train)\n",
    "        test_scores.append(r2_test)\n",
    "        models.append(model)\n",
    "\n",
    "    return models, train_scores, test_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test di differenti pipelines\n",
    "\n",
    "configs = [\n",
    "    Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"lasso\", Lasso(alpha=0.1))\n",
    "    ]),\n",
    "    Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"ridge\", Ridge(alpha=0.1))\n",
    "    ]),\n",
    "    Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"lasso\", Lasso(alpha=0.2))\n",
    "    ]),\n",
    "    Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"ridge\", Ridge(alpha=0.2))\n",
    "    ]),\n",
    "    Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=2)),\n",
    "        (\"lr\", LinearRegression())\n",
    "    ])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing config Pipeline(steps=[('poly', PolynomialFeatures()), ('lasso', Lasso(alpha=0.1))]):\n",
      "\n",
      "Mean train score: 0.7849360249833668\n",
      "Mean test score: 0.6847705441719817\n",
      "\n",
      "\n",
      "Testing config Pipeline(steps=[('poly', PolynomialFeatures()), ('ridge', Ridge(alpha=0.1))]):\n",
      "\n",
      "Mean train score: 0.841627356333705\n",
      "Mean test score: 0.42057457061163417\n",
      "\n",
      "\n",
      "Testing config Pipeline(steps=[('poly', PolynomialFeatures()), ('lasso', Lasso(alpha=0.2))]):\n",
      "\n",
      "Mean train score: 0.7507830824572747\n",
      "Mean test score: 0.6809101649667221\n",
      "\n",
      "\n",
      "Testing config Pipeline(steps=[('poly', PolynomialFeatures()), ('ridge', Ridge(alpha=0.2))]):\n",
      "\n",
      "Mean train score: 0.8369776550537507\n",
      "Mean test score: 0.6159477597277367\n",
      "\n",
      "\n",
      "Testing config Pipeline(steps=[('poly', PolynomialFeatures()), ('lr', LinearRegression())]):\n",
      "\n",
      "Mean train score: 0.8428374247674715\n",
      "Mean test score: 0.5055044250282832\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creazione del modello polinomiale di 2o grado\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"Testing config {config}:\\n\")\n",
    "    models, train_scores, test_scores = cross_validation(X, Y, pipeline=config)\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    train_scores.append(train_scores)\n",
    "    test_scores.append(test_scores)\n",
    "\n",
    "print(f\"Mean train score: {np.mean(train_scores)}\")\n",
    "print(f\"Mean test score: {np.mean(test_scores)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "    # for model in models:\n",
    "    #     print(f\"Model {config}:\")\n",
    "    #     evaluate_model(model, (X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning curve\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
